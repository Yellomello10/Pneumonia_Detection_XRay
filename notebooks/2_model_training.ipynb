{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c435e930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "Libraries imported successfully (using src modules).\n"
     ]
    }
   ],
   "source": [
    "# --- Notebook: 2_model_training.ipynb ---\n",
    "\n",
    "# --- 1. Import Libraries ---\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "# Core ML framework import (still needed for some direct calls like preprocess_input)\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import functions from your custom src modules\n",
    "from src.data_processing import get_image_data_generators, compute_class_weights\n",
    "from src.model import build_transfer_model, compile_model, unfreeze_and_recompile_model\n",
    "# from src.utils import plot_training_history # Uncomment if you put plotting functions in src.utils\n",
    "\n",
    "# Specific Keras imports for callbacks (since they are instantiated directly here)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Note: We no longer need to import Dense, GlobalAveragePooling2D, Input, ResNet50,\n",
    "#       Adam, BinaryCrossentropy, BinaryAccuracy, Precision, Recall, l2 directly here,\n",
    "#       because they are now imported and used *inside* the functions in src/model.py.\n",
    "\n",
    "# For calculating class weights (still needed directly here for compute_class_weight)\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(\"Libraries imported successfully (using src modules).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c732275f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying Data Directory Paths ---\n",
      "Train directory exists: True\n",
      "Validation directory exists: True\n",
      "Test directory exists: True\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Define Data Paths\n",
    "base_dir = 'M:\\Downloads\\Pneumonia_Detection_XRay\\Pneumonia_Detection_XRay\\data\\chest_xray'  \n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Verify that the directories exist\n",
    "print(\"\\n--- Verifying Data Directory Paths ---\")\n",
    "print(f\"Train directory exists: {os.path.exists(train_dir)}\")\n",
    "print(f\"Validation directory exists: {os.path.exists(val_dir)}\")\n",
    "print(f\"Test directory exists: {os.path.exists(test_dir)}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02319a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Setting up Data Generators using src.data_processing ---\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Data Preprocessing and Augmentation ---\n",
    "\n",
    "# Define Image Size - ResNet50 typically expects 224x224\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32 # Common batch size, adjust based on GPU memory\n",
    "NUM_CLASSES = 1 # Binary classification (Pneumonia or Normal)\n",
    "\n",
    "# ResNet50's preprocess_input function\n",
    "# This function rescales input pixels to [-1, 1], which is common for models pre-trained on ImageNet\n",
    "preprocess_input = tf.keras.applications.resnet50.preprocess_input # <--- Make sure tf is imported!\n",
    "\n",
    "print(\"\\n--- Setting up Data Generators using src.data_processing ---\")\n",
    "train_generator, validation_generator, test_generator = get_image_data_generators(\n",
    "    train_dir, val_dir, test_dir, IMG_HEIGHT, IMG_WIDTH, BATCH_SIZE, preprocess_input\n",
    ")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc88cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Computing Class Weights using src.data_processing ---\n",
      "\n",
      "Computed Class Weights (for training imbalance): {0: 1.9448173005219984, 1: 0.6730322580645162}\n",
      "This means misclassifying the minority class will be penalized more during training.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 3.1. Handle Class Imbalance with Class Weights ---\n",
    "print(\"\\n--- Computing Class Weights using src.data_processing ---\")\n",
    "class_weights_dict = compute_class_weights(train_generator)\n",
    "\n",
    "print(f\"\\nComputed Class Weights (for training imbalance): {class_weights_dict}\")\n",
    "print(\"This means misclassifying the minority class will be penalized more during training.\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fda3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Building Model with ResNet50 Base and Custom Head (Dropout: 0.0, L2: 0.0) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,112,513</span> (91.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,112,513\u001b[0m (91.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">524,801</span> (2.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m524,801\u001b[0m (2.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 4 & 5. Load Pre-trained Model & Add Custom Classification Head (using src.model) ---\n",
    "# Define regularization parameters (consistent with src/model.py defaults or your tuning)\n",
    "DROPOUT_RATE = 0.0 # Start with 0.0 (no dropout) for initial testing if you want, then tune. Recommended: 0.4\n",
    "L2_STRENGTH = 0.0 # Start with 0.0 (no L2) for initial testing if you want, then tune. Recommended: 0.001\n",
    "\n",
    "print(f\"\\n--- Building Model with ResNet50 Base and Custom Head (Dropout: {DROPOUT_RATE}, L2: {L2_STRENGTH}) ---\")\n",
    "\n",
    "# This single line calls the function from src/model.py which defines the inputs,\n",
    "# connects base_model, adds pooling, dense layers, dropout, and the output layer.\n",
    "# It returns the complete 'model' and the 'base_model' instance.\n",
    "model, base_model = build_transfer_model(IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES,\n",
    "                                         dropout_rate=DROPOUT_RATE, l2_strength=L2_STRENGTH)\n",
    "\n",
    "model.summary() # Print summary here\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c2b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Compiling Model (Phase 1: Frozen Layers) ---\n",
      "Model compiled for Phase 1 (Frozen Layers).\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Compile the Model (Phase 1: Frozen Layers) (using src.model) ---\n",
    "print(\"\\n--- Compiling Model (Phase 1: Frozen Layers) ---\")\n",
    "initial_learning_rate = 1e-4 # Define your learning rate here\n",
    "\n",
    "model = compile_model(model, initial_learning_rate)\n",
    "print(\"Model compiled for Phase 1 (Frozen Layers).\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "665c7e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training (Phase 1: Frozen Layers) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melwin\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8354 - loss: 0.3213 - precision: 0.9424 - recall: 0.8309\n",
      "Epoch 1: val_accuracy improved from -inf to 0.93750, saving model to ../models\\best_model_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 2s/step - accuracy: 0.8358 - loss: 0.3206 - precision: 0.9426 - recall: 0.8314 - val_accuracy: 0.9375 - val_loss: 0.2141 - val_precision: 1.0000 - val_recall: 0.8750\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9502 - loss: 0.1241 - precision: 0.9900 - recall: 0.9417\n",
      "Epoch 2: val_accuracy did not improve from 0.93750\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 2s/step - accuracy: 0.9502 - loss: 0.1240 - precision: 0.9900 - recall: 0.9418 - val_accuracy: 0.9375 - val_loss: 0.1523 - val_precision: 0.8889 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9601 - loss: 0.0913 - precision: 0.9895 - recall: 0.9565\n",
      "Epoch 3: val_accuracy did not improve from 0.93750\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 2s/step - accuracy: 0.9601 - loss: 0.0913 - precision: 0.9895 - recall: 0.9565 - val_accuracy: 0.8750 - val_loss: 0.1483 - val_precision: 0.8000 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9602 - loss: 0.1035 - precision: 0.9892 - recall: 0.9575\n",
      "Epoch 4: val_accuracy improved from 0.93750 to 1.00000, saving model to ../models\\best_model_phase1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 2s/step - accuracy: 0.9602 - loss: 0.1035 - precision: 0.9893 - recall: 0.9575 - val_accuracy: 1.0000 - val_loss: 0.0831 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9683 - loss: 0.0818 - precision: 0.9908 - recall: 0.9661\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 2s/step - accuracy: 0.9683 - loss: 0.0818 - precision: 0.9908 - recall: 0.9661 - val_accuracy: 1.0000 - val_loss: 0.0688 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9713 - loss: 0.0670 - precision: 0.9931 - recall: 0.9680\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 2s/step - accuracy: 0.9713 - loss: 0.0671 - precision: 0.9931 - recall: 0.9680 - val_accuracy: 1.0000 - val_loss: 0.0544 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9740 - loss: 0.0693 - precision: 0.9916 - recall: 0.9736\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 2s/step - accuracy: 0.9740 - loss: 0.0693 - precision: 0.9916 - recall: 0.9736 - val_accuracy: 1.0000 - val_loss: 0.0567 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9656 - loss: 0.0922 - precision: 0.9913 - recall: 0.9623\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 2s/step - accuracy: 0.9657 - loss: 0.0921 - precision: 0.9913 - recall: 0.9623 - val_accuracy: 1.0000 - val_loss: 0.0617 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9772 - loss: 0.0587 - precision: 0.9918 - recall: 0.9774\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 2s/step - accuracy: 0.9772 - loss: 0.0588 - precision: 0.9918 - recall: 0.9774 - val_accuracy: 1.0000 - val_loss: 0.0894 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9765 - loss: 0.0653 - precision: 0.9953 - recall: 0.9729\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 2s/step - accuracy: 0.9765 - loss: 0.0653 - precision: 0.9953 - recall: 0.9729 - val_accuracy: 1.0000 - val_loss: 0.0566 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\n",
      "Phase 1 Training Complete. Best model saved to 'best_model_phase1.h5'.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Train the Model (Phase 1: Frozen Layers) --- \n",
    "print(\"\\n--- Starting Training (Phase 1: Frozen Layers) ---\")\n",
    "\n",
    "# Define callbacks\n",
    "model_checkpoint_callback_phase1 = ModelCheckpoint(\n",
    "    filepath=os.path.join('../models', 'best_model_phase1.h5'), # Save model to models/ folder\n",
    "    monitor='val_accuracy', # Monitor validation accuracy\n",
    "    save_best_only=True,    # Save only the best model\n",
    "    mode='max',             # Maximize validation accuracy\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping_callback_phase1 = EarlyStopping(\n",
    "    monitor='val_loss', # Monitor validation loss\n",
    "    patience=5,         # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True, # Restore model weights from the epoch with the best value of the monitored quantity.\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Number of epochs for initial training\n",
    "EPOCHS_PHASE1 = 10 # Start with a reasonable number, early stopping will prevent overfitting\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS_PHASE1,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights_dict, # Apply class weights to handle imbalance\n",
    "    callbacks=[model_checkpoint_callback_phase1, early_stopping_callback_phase1],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nPhase 1 Training Complete. Best model saved to 'best_model_phase1.h5'.\")\n",
    "print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "babc79da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Fine-tuning (Phase 2: Unfrozen Layers) ---\n",
      "\n",
      "--- Unfreezing and Recompiling Model for Phase 2 (Fine-tuning) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,112,513</span> (91.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,112,513\u001b[0m (91.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,443,841</span> (36.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,443,841\u001b[0m (36.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,668,672</span> (55.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,668,672\u001b[0m (55.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Epoch 1/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9659 - loss: 0.0815 - precision: 0.9897 - recall: 0.9645\n",
      "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to ../models\\final_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 2s/step - accuracy: 0.9659 - loss: 0.0815 - precision: 0.9897 - recall: 0.9645 - val_accuracy: 1.0000 - val_loss: 0.0611 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9694 - loss: 0.0689 - precision: 0.9950 - recall: 0.9640\n",
      "Epoch 2: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 2s/step - accuracy: 0.9694 - loss: 0.0689 - precision: 0.9950 - recall: 0.9640 - val_accuracy: 1.0000 - val_loss: 0.0757 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9765 - loss: 0.0541 - precision: 0.9955 - recall: 0.9730\n",
      "Epoch 3: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 2s/step - accuracy: 0.9765 - loss: 0.0542 - precision: 0.9955 - recall: 0.9730 - val_accuracy: 1.0000 - val_loss: 0.0671 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9789 - loss: 0.0502 - precision: 0.9958 - recall: 0.9757\n",
      "Epoch 4: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 2s/step - accuracy: 0.9789 - loss: 0.0502 - precision: 0.9958 - recall: 0.9757 - val_accuracy: 1.0000 - val_loss: 0.0526 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9827 - loss: 0.0430 - precision: 0.9960 - recall: 0.9804\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 2s/step - accuracy: 0.9827 - loss: 0.0430 - precision: 0.9960 - recall: 0.9804 - val_accuracy: 1.0000 - val_loss: 0.0365 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9791 - loss: 0.0527 - precision: 0.9923 - recall: 0.9793\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 2s/step - accuracy: 0.9791 - loss: 0.0526 - precision: 0.9924 - recall: 0.9793 - val_accuracy: 1.0000 - val_loss: 0.0678 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9845 - loss: 0.0362 - precision: 0.9960 - recall: 0.9828\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.0362 - precision: 0.9960 - recall: 0.9828 - val_accuracy: 1.0000 - val_loss: 0.0357 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9847 - loss: 0.0359 - precision: 0.9967 - recall: 0.9830\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 2s/step - accuracy: 0.9847 - loss: 0.0359 - precision: 0.9967 - recall: 0.9830 - val_accuracy: 1.0000 - val_loss: 0.0632 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9869 - loss: 0.0297 - precision: 0.9966 - recall: 0.9858\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 2s/step - accuracy: 0.9869 - loss: 0.0298 - precision: 0.9966 - recall: 0.9858 - val_accuracy: 1.0000 - val_loss: 0.0992 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9879 - loss: 0.0309 - precision: 0.9968 - recall: 0.9867\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 2s/step - accuracy: 0.9879 - loss: 0.0309 - precision: 0.9968 - recall: 0.9867 - val_accuracy: 1.0000 - val_loss: 0.0390 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9863 - loss: 0.0287 - precision: 0.9955 - recall: 0.9862\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 2s/step - accuracy: 0.9863 - loss: 0.0286 - precision: 0.9955 - recall: 0.9862 - val_accuracy: 1.0000 - val_loss: 0.0205 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 12/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9917 - loss: 0.0234 - precision: 0.9972 - recall: 0.9915\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 2s/step - accuracy: 0.9917 - loss: 0.0234 - precision: 0.9972 - recall: 0.9915 - val_accuracy: 1.0000 - val_loss: 0.0079 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 13/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9905 - loss: 0.0195 - precision: 0.9987 - recall: 0.9886\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 2s/step - accuracy: 0.9905 - loss: 0.0195 - precision: 0.9986 - recall: 0.9886 - val_accuracy: 1.0000 - val_loss: 0.0169 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 14/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9918 - loss: 0.0252 - precision: 0.9976 - recall: 0.9913\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - accuracy: 0.9918 - loss: 0.0252 - precision: 0.9976 - recall: 0.9913 - val_accuracy: 1.0000 - val_loss: 0.0065 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 15/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9871 - loss: 0.0257 - precision: 0.9971 - recall: 0.9854\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - accuracy: 0.9871 - loss: 0.0257 - precision: 0.9971 - recall: 0.9854 - val_accuracy: 1.0000 - val_loss: 0.0111 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 16/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9922 - loss: 0.0217 - precision: 0.9960 - recall: 0.9936\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 2s/step - accuracy: 0.9922 - loss: 0.0217 - precision: 0.9961 - recall: 0.9936 - val_accuracy: 1.0000 - val_loss: 0.0068 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 17/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9929 - loss: 0.0201 - precision: 0.9986 - recall: 0.9918\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 2s/step - accuracy: 0.9929 - loss: 0.0200 - precision: 0.9986 - recall: 0.9918 - val_accuracy: 1.0000 - val_loss: 0.0063 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 18/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9927 - loss: 0.0248 - precision: 0.9981 - recall: 0.9919\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 2s/step - accuracy: 0.9927 - loss: 0.0248 - precision: 0.9981 - recall: 0.9919 - val_accuracy: 1.0000 - val_loss: 0.0037 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 19/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9925 - loss: 0.0220 - precision: 0.9988 - recall: 0.9912\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 2s/step - accuracy: 0.9925 - loss: 0.0220 - precision: 0.9988 - recall: 0.9912 - val_accuracy: 1.0000 - val_loss: 0.0038 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 20/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9938 - loss: 0.0187 - precision: 0.9991 - recall: 0.9926\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 2s/step - accuracy: 0.9938 - loss: 0.0187 - precision: 0.9991 - recall: 0.9926 - val_accuracy: 1.0000 - val_loss: 0.0039 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 21/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9938 - loss: 0.0182 - precision: 0.9988 - recall: 0.9930\n",
      "Epoch 21: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 2s/step - accuracy: 0.9938 - loss: 0.0182 - precision: 0.9988 - recall: 0.9930 - val_accuracy: 1.0000 - val_loss: 0.0028 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 22/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9926 - loss: 0.0175 - precision: 0.9980 - recall: 0.9919\n",
      "Epoch 22: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 2s/step - accuracy: 0.9926 - loss: 0.0174 - precision: 0.9980 - recall: 0.9919 - val_accuracy: 1.0000 - val_loss: 0.0026 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 23/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9921 - loss: 0.0201 - precision: 0.9980 - recall: 0.9914\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 2s/step - accuracy: 0.9921 - loss: 0.0201 - precision: 0.9980 - recall: 0.9914 - val_accuracy: 1.0000 - val_loss: 0.0029 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 24/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9939 - loss: 0.0187 - precision: 0.9995 - recall: 0.9922\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - accuracy: 0.9939 - loss: 0.0187 - precision: 0.9995 - recall: 0.9922 - val_accuracy: 1.0000 - val_loss: 0.0077 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 25/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9952 - loss: 0.0131 - precision: 0.9993 - recall: 0.9942\n",
      "Epoch 25: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - accuracy: 0.9952 - loss: 0.0132 - precision: 0.9993 - recall: 0.9942 - val_accuracy: 1.0000 - val_loss: 0.0047 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-06\n",
      "Epoch 26/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9927 - loss: 0.0152 - precision: 0.9985 - recall: 0.9917\n",
      "Epoch 26: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - accuracy: 0.9927 - loss: 0.0152 - precision: 0.9985 - recall: 0.9917 - val_accuracy: 1.0000 - val_loss: 0.0049 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 4.0000e-07\n",
      "Epoch 27/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9937 - loss: 0.0205 - precision: 0.9974 - recall: 0.9942\n",
      "Epoch 27: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 2s/step - accuracy: 0.9937 - loss: 0.0205 - precision: 0.9974 - recall: 0.9942 - val_accuracy: 1.0000 - val_loss: 0.0044 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 4.0000e-07\n",
      "Epoch 28/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9888 - loss: 0.0298 - precision: 0.9945 - recall: 0.9903\n",
      "Epoch 28: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 2s/step - accuracy: 0.9888 - loss: 0.0298 - precision: 0.9946 - recall: 0.9903 - val_accuracy: 1.0000 - val_loss: 0.0034 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 4.0000e-07\n",
      "Epoch 29/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9934 - loss: 0.0161 - precision: 0.9989 - recall: 0.9922\n",
      "Epoch 29: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 3s/step - accuracy: 0.9934 - loss: 0.0161 - precision: 0.9989 - recall: 0.9922 - val_accuracy: 1.0000 - val_loss: 0.0032 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-07\n",
      "Epoch 30/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9934 - loss: 0.0147 - precision: 0.9982 - recall: 0.9926\n",
      "Epoch 30: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 3s/step - accuracy: 0.9934 - loss: 0.0147 - precision: 0.9982 - recall: 0.9926 - val_accuracy: 1.0000 - val_loss: 0.0032 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-07\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "\n",
      "Phase 2 Fine-tuning Complete. Best model saved to 'final_best_model.h5'.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Fine-tuning (Phase 2: Unfrozen Layers) ---\n",
    "print(\"\\n--- Starting Fine-tuning (Phase 2: Unfrozen Layers) ---\")\n",
    "\n",
    "# Load the best weights from Phase 1 before fine-tuning\n",
    "model.load_weights(os.path.join('../models', 'best_model_phase1.h5'))\n",
    "\n",
    "# ... (model.load_weights line) ...\n",
    "\n",
    "# Define fine-tuning parameters\n",
    "NUM_UNFREEZE_LAYERS = 20 # Tune this\n",
    "fine_tune_learning_rate = 1e-5 # Tune this\n",
    "\n",
    "print(f\"\\n--- Unfreezing and Recompiling Model for Phase 2 (Fine-tuning) ---\")\n",
    "model = unfreeze_and_recompile_model(model, base_model, fine_tune_learning_rate, NUM_UNFREEZE_LAYERS)\n",
    "model.summary() # See which layers are now trainable\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Define callbacks for Phase 2\n",
    "model_checkpoint_callback_phase2 = ModelCheckpoint(\n",
    "    filepath=os.path.join('../models', 'final_best_model.h5'), # Save final best model\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping_callback_phase2 = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=8, # Slightly more patience for fine-tuning\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2, # Reduce learning rate by a factor of 0.2\n",
    "    patience=3, # If val_loss doesn't improve for 3 epochs, reduce LR\n",
    "    min_lr=1e-7, # Minimum learning rate\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "EPOCHS_PHASE2 = 30 # More epochs for fine-tuning, early stopping will manage it\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS_PHASE2,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights_dict, # Continue applying class weights\n",
    "    callbacks=[\n",
    "        model_checkpoint_callback_phase2,\n",
    "        early_stopping_callback_phase2,\n",
    "        reduce_lr_on_plateau\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nPhase 2 Fine-tuning Complete. Best model saved to 'final_best_model.h5'.\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a33956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training history saved to ../models\\training_history.csv\n",
      "Final model (last state) saved to ../models\\trained_pneumonia_detector.h5\n",
      "\n",
      "--- Training Notebook Execution Complete ---\n",
      "You can now proceed to `3_model_evaluation.ipynb` to evaluate your best model.\n"
     ]
    }
   ],
   "source": [
    "# --- 9. Save Training History ---\n",
    "# Combine history from both phases (if applicable) and save\n",
    "history_df_phase1 = pd.DataFrame(history_phase1.history)\n",
    "history_df_phase2 = pd.DataFrame(history_phase2.history)\n",
    "\n",
    "# Adjust epoch numbers for phase 2 to be continuous\n",
    "history_df_phase2.index = history_df_phase2.index + len(history_df_phase1)\n",
    "\n",
    "# Concatenate histories\n",
    "full_history_df = pd.concat([history_df_phase1, history_df_phase2])\n",
    "\n",
    "history_save_path = os.path.join('../models', 'training_history.csv')\n",
    "full_history_df.to_csv(history_save_path, index=False)\n",
    "print(f\"\\nTraining history saved to {history_save_path}\")\n",
    "\n",
    "# --- 10. Final Model Saving (Redundant if checkpointing works, but good practice) ---\n",
    "# If you want to ensure the final state of the model (after all callbacks) is saved\n",
    "final_model_path = os.path.join('../models', 'trained_pneumonia_detector.h5')\n",
    "model.save(final_model_path)\n",
    "print(f\"Final model (last state) saved to {final_model_path}\")\n",
    "\n",
    "print(\"\\n--- Training Notebook Execution Complete ---\")\n",
    "print(\"You can now proceed to `3_model_evaluation.ipynb` to evaluate your best model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
